# kaggleコンペ　議事録

kaggleからコンペを1つ選び、submitしてください。
どういう工夫を行い、どういう結果になったかを説明してください。
うまくいかなくてもかまいません。何かしら工夫してみてもらえれば大丈夫です。

【チェックしている観点】
改善策を試行錯誤できる力
機械学習の実装力

# 方針
## ベースカーネル　lightbgmを使っているカーネルを中心に手法を勉強
https://www.kaggle.com/code/kyakovlev/ieee-gb-2-make-amount-useful-again/notebook?scriptVersionId=19402773  
https://www.kaggle.com/code/nroman/lgb-single-model-lb-0-9419/notebook
https://www.kaggle.com/code/timon88/lgbm-baseline-small-fe-no-blend/notebook

詐欺であるか否かを判定するのでクラス分類で考える
classificationのとこらからモデルを決める
【アルゴリズムのフローチャートを参考に↓】
![image](https://github.com/Yuma-Tsukakoshi/CrossViT-Summary-/assets/107422037/2d575e66-43d5-4540-a748-079d618651ab)

データ量的は約60万ものデータが使用されている
⇒SGD Classfire もしうまくいかなかったらkernel aproximinate
⇒lightGBMによって高速に処理する方針で

# 工程
## 【ライブラリのインポート】
- numpy:行列や配列を扱う  
- pandas: データフレームを扱う  
- gc: garbagecollectionをすることでメモリリークを防ぐ⇒今回データが膨大であるためメモリの解法を行うため使用
- datetime: 今回扱う日時に関するデータは、投稿からの経過秒数が格納されているため実際の日時ではないため日時変換で扱う

- metrics = 
- train_test_split = テストと訓練の分割
- KFold = 
- LabelEncoder =

## 変数の設定
TARGET → 今回のターゲットカラムを設定
SEED → ランダムで結果が毎回同じになるようにSEEDを設定
START_DATE → このデータの集計が始まった日付を設定し、先ほどインポートしたdatetimeで秒数に直す

## 【 データの読み込み】
データ処理→一旦追う

## 【 特徴量の準備】


## 1.前処理・特徴量エンジニアリング
前処理に時間がかかるというのに非常に痛感した。
データを見ただけだと、どのデータとどのデータが関係しているのかとか、
欠損値や外れ値にどのようなアプローチを施すのが最適なのかなど、手が動かず半日何も進まない日もあった。
結果的には参考カーネルのような高い精度が出なかった。
調べた結果、ランキング上位者の手法で共通している点があった
・ユーザーを特定している　→ 手法がわからなかった
・データの不均衡さの改善
→ オーバーサンプリングやアンダーサンプリングを行う
→ 詐欺であると認証したデータが圧倒的に少なかった
→サンプリングしてみたが上手くいかなかったので、実際に調べたらいい塩梅でやる必要があるらしくそこの方法までは行きつかなかった。





## 2.機械学習アルゴリズム
*LightGBM* か *XGBoost*　などの勾配ブースティング系のモデルが使われる

## 3.パラメータチューニング特徴量選択

###  分析仮定
- 通常の取引と比べて、金額や頻度が異常に高いか低い  
⇒金額が極端。  
⇒また、特定の時間帯や曜日に集中して発生する可能性が高い。
  　
- 特定のカードやメールアドレスなどの識別子に関連して発生する可能性が高い。  
⇒ex) 同じカード番号やメールアドレスで複数の取引を行ったり、異なる国や地域で取引を行ったりする場合
  
- 特定の業種や業界に関連して発生する可能性が高い。  
⇒ex) 医療や教育などの公共サービスや、金融や不動産などの高額な取引が多い業種。
  
- 特定の顧客や従業員に関連して発生する可能性が高い。  
⇒ex) 顧客の中には、不正な手段でサービスを受けたり、返金や補償を要求する人がいる。

- 特定の商品などをターゲットとしている可能性が高い
⇒今回商品に関するデータはなかったので断念


# 工夫点
・

# 結果
・
