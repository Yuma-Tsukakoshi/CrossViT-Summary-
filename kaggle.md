# kaggleコンペ　議事録
【チェックしている観点】
改善策を試行錯誤できる力
機械学習の実装力

# 方針
## ベースカーネル　lightbgmを使っているカーネルを中心に手法を勉強
https://www.kaggle.com/code/kyakovlev/ieee-gb-2-make-amount-useful-again/notebook?scriptVersionId=19402773  
https://www.kaggle.com/code/nroman/lgb-single-model-lb-0-9419/notebook
https://www.kaggle.com/code/timon88/lgbm-baseline-small-fe-no-blend/notebook

詐欺であるか否かを判定するのでクラス分類で考える
classificationのとこらからモデルを決める
【アルゴリズムのフローチャートを参考に↓】
![image](https://github.com/Yuma-Tsukakoshi/CrossViT-Summary-/assets/107422037/2d575e66-43d5-4540-a748-079d618651ab)

データ量的は約60万ものデータが使用されている
⇒SGD Classfire もしうまくいかなかったらkernel aproximinate
⇒lightGBMによって高速に処理する方針で

# 工程
## 【ライブラリのインポート】
- numpy:行列や配列を扱う  
- pandas: データフレームを扱う  
- gc: garbagecollectionをすることでメモリリークを防ぐ⇒今回データが膨大であるためメモリの解法を行うため使用
- datetime: 今回扱う日時に関するデータは、投稿からの経過秒数が格納されているため実際の日時ではないため日時変換で扱う
　　
- metrics = 
- train_test_split = テストと訓練の分割
- KFold = 
- LabelEncoder =

## 変数の設定
TARGET → 今回のターゲットカラムを設定
SEED → ランダムで結果が毎回同じになるようにSEEDを設定
START_DATE → このデータの集計の初日の日付を設定し、先ほどインポートしたdatetimeでフォーマットをそろえる

=================================================================================

# 説明内容
## 取り組んだコンペについて
・クレジットカードの取引データを用いて、不正な取引を検出することを目的に行いました。
既に終了しているコンペであったのだが、自然言語処理や画像処理ではなくデータ分析に絞って色々コンペを探した結果、直感的に分析するのが面白そうだと興味を持った。

## コンペの結果
submitした出力スコアは0.91でした。順位に換算すると3000位ほどでした。

## 実装方法方針
kaggleを今までやったことがなかったが、AI課題リストの10のカーネルを実装し大体の大枠をつかんだ後に取り組んだ。まず、discussionを見てどのようなコンペなのかを把握したり、実際にネットで参加者からの意見などから概要をつかんでいきました。その後ベースとなるカーネルをいくつか探しデータ分析を行いました。

## 工夫点
### データの準備方法




データを眺めても何からコードを書いていけばよいかがわからなかった。
そのため、与えられてデータのカラムを基にどのようなデータの傾向を読み取れば不正取引だと判断できるのかを仮説を考えた。



### 1つ目 不正な取引は特定の時間帯や曜日に集中して発生する可能性が高いこと。
DTカラムから、取引が行われた年、月、日を取得し新たにカラムを追加している。
また、D9のカラムは取引からの経過時間が格納されているので、不明で欠損値となっている場合は不正が働いていると考えることにつながる。

### 2つ目 不正な取引は特定のカードやメールアドレスなどの識別子に関連して発生する可能性が高いこと。
まず初めに欠損値を文字列で埋め、その後にメールアドレスの一致判定を行っている。
行った背景としては、購入者と受取人が同一人物(アドレスが同じ)だと、不正の確率低い   
⇔ 購入者と受取人が別人だと、不正の確率が高いと思ったから
子分が各地で購入し、親がすべて受けとるみたいな状況をイメージ

### 3つ目 不正な取引は特定のデバイスやブラウザが不正行為に使われやすいこと。
(工夫点として、trainデータとtestデータのカラム名が異なっていたので前処理を行った。)
DeviceInfoの値
discussionから、id_30の値はバージョンを含んだデバイスの情報を、id_31の情報はブラウザの情報を格納していることがわかった。

### 用いたモデル

用いた背景としては、

### 難しかった点　課題点
前処理に時間がかかるというのに非常に痛感した。
データを見ただけだと、どのデータとどのデータが関係しているのかとか、
欠損値や外れ値にどのようなアプローチを施すのが最適なのかなど、手が動かず半日何も進まない日もあった。
結果的には参考カーネルのような高い精度が出なかった。
調べた結果、ランキング上位者の手法で共通している点があった
・ユーザーを特定している　→ 手法がわからなかった
・データの不均衡さの改善
→ オーバーサンプリングやアンダーサンプリングを行う
→ 詐欺であると認証したデータが圧倒的に少なかった
→サンプリングしてみたが上手くいかなかったので、実際に調べたらいい塩梅でやる必要があるらしくそこの方法までは行きつかなかった。
