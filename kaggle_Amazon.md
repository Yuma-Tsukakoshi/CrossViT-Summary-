# kaggleで公式ドキュメント解読しながらsikit_learn実装
  
## 分析コンペにおけるタスクの種類
⇒ 二値分類  
⇒ アクセス権限を与えるかどうか 0/1   

## 評価指標
- ROC：  
正例が非常に少ない不均衡データの場合、正例の予測値をどれだけ高確率の側に寄せることができるかが、AUC に大きく影響する。  
逆に、負例の予測値の誤差の影響はあまり大きくない

## 評価指標の最適化
- 2.6.5 MCCのPR-AUCによる近似とモデル選択
### 使い所： 極度の不均衡データがある場合
ex) 6000 : 1000000 = 正例 : 負例　の場合  
![image](https://github.com/Yuma-Tsukakoshi/CrossViT-Summary-/assets/107422037/6f5e6a13-f3d2-4a23-876d-7e7058ede43c)  
ほとんどがROCにおいてTNがy軸に張り付く事態に、、、 分母がでかく偽陽性があったとしても0に近くなってしまう  
⇒ PR曲線の下側面崎で定義されるPR-AUCを用いることで解決する  
⇒最適な閾値におけるMCCと大局的に良い相関を示しつつもモデルの性能を評価できている  

### 期待できること：  
PR-AUC は、MCCより安定しているので特徴選択の結果に対して実験結果の一貫性が向上し、
閾値の最適化が必要ないので検討スループットの向上が期待できる。
今回の評価指標はMCCではないので使えないが大事な考え方！

## 特徴量の生成
交差検証を行う場合はKFoldを行って、foldごとに目的変数を用いないで学習を行うことが大切

同じようなデータを持つモノはグループ化してカテゴリをまとめて扱うこともできる

勾配boostigの場合、欠損値の扱いは気にしなくて良い！また、one-hot encodingもしなくて良い
⇒ 今回の場合だと、そもそも値がカテゴリ変数をそのまま扱うことができるため

frequent encodingをすると精度が上がる可能性がある  
⇒ Frequency encodingを使うと、精度が上がることがある理由は、以下のようなものが考えられます。  
頻度が高いカテゴリは、目的変数との関係が強い可能性が高いため、モデルがその情報を捉えやすくなる。  
頻度が低いカテゴリは、ノイズや外れ値として扱われる可能性が高いため、モデルがその影響を無視しやすくなる。  
Frequency encodingでは、頻度に基づいて順序が付けられるため、分割点を見つけやすくなります。
