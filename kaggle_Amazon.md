# kaggleで公式ドキュメント解読しながらsikit_learn実装
  
## 分析コンペにおけるタスクの種類
⇒ 二値分類  
⇒ アクセス権限を与えるかどうか 0/1   

## 評価指標
- ROC：  
正例が非常に少ない不均衡データの場合、正例の予測値をどれだけ高確率の側に寄せることができるかが、AUC に大きく影響する。  
逆に、負例の予測値の誤差の影響はあまり大きくない

## 評価指標の最適化
- 2.6.5 MCCのPR-AUCによる近似とモデル選択
### 使い所： 極度の不均衡データがある場合
ex) 6000 : 1000000 = 正例 : 負例　の場合  
![image](https://github.com/Yuma-Tsukakoshi/CrossViT-Summary-/assets/107422037/6f5e6a13-f3d2-4a23-876d-7e7058ede43c)  
ほとんどがROCにおいてTNがy軸に張り付く事態に、、、 分母がでかく偽陽性があったとしても0に近くなってしまう  
⇒ PR曲線の下側面崎で定義されるPR-AUCを用いることで解決する  
⇒最適な閾値におけるMCCと大局的に良い相関を示しつつもモデルの性能を評価できている  

### 期待できること：  
PR-AUC は、MCCより安定しているので特徴選択の結果に対して実験結果の一貫性が向上し、
閾値の最適化が必要ないので検討スループットの向上が期待できる。
今回の評価指標はMCCではないので使えないが大事な考え方！

## 特徴量の生成
交差検証を行う場合はKFoldを行って、foldごとに目的変数を用いないで学習を行うことが大切

同じようなデータを持つモノはグループ化してカテゴリをまとめて扱うこともできる

勾配boostigの場合、欠損値の扱いは気にしなくて良い！また、one-hot encodingもしなくて良い
⇒ 今回の場合だと、そもそも値がカテゴリ変数をそのまま扱うことができるため

frequent encodingをすると精度が上がる可能性がある  
⇒ Frequency encodingを使うと、精度が上がることがある理由は、以下のようなものが考えられます。  
頻度が高いカテゴリは、目的変数との関係が強い可能性が高いため、モデルがその情報を捉えやすくなる。  
頻度が低いカテゴリは、ノイズや外れ値として扱われる可能性が高いため、モデルがその影響を無視しやすくなる。  
Frequency encodingでは、頻度に基づいて順序が付けられるため、分割点を見つけやすくなる。

## xgboostのパラメータチューニング
- 目的関数 : binary:logisticを設定
- 二値分類の場合は : loglossを指定し最小化するように学習


## 前処理の実装コツ
## 不均衡データに対する前処理方法
- アンダーサンプリング
    - 少ない方にデータ量を合わせる手法。
    - ただ、バイアスがかかってしまうので、アンダーバギングによってアンサンブルに学習させる
- オーバーサンプリング
    - 多いほうにデータ量を合わせる手法。
    - SMOTE (Synthetic Minority Oversampling TEchnique): 近傍点からサンプルを生成する
- 重み付け
    - 少数派のサンプルに重み付けを行い（重要視して）、少数派のカテゴリをより的確に分類できるようにする手法
    例えば決定木系のモデルでは、損失関数を元に分類を行いますが、そもそも正例または負例のサンプル少ない場合は、損失に影響を及ぼしにくい為、重み付けを行う必要があります。
    - データ量の増加は発生しない⇒メモリの節約ができる


## Leaderboard 参照　先
- rank1 Dmitry Efimov
  url[ rank1のLeaderBoard ](https://www.kaggle.com/competitions/amazon-employee-access-challenge/discussion/5283)



## Codeのmost Voteでソートし6つ選択
・疎結合のデータ
・
