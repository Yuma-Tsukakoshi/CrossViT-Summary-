# 論文要約
論文の内容の理解度
自分がわかっていないことを自覚する力（自分が理解できていないことを認める強さ）  
論文を読むだけではわからないことを自力で調べる力  
批判的な視点、観点

今回の論文を簡単に述べると以下のようになる！  
画像を小さく切って、それぞれに番号をつける。  
小さい番号の画像は速く処理する。大きい番号の画像はゆっくり処理する。  
小さい番号と大きい番号の画像を何回か混ぜて、新しい画像を作る。  
新しい画像は元の画像よりもっと良くなる。  

=================================================================================
# 背景
今回、私が選んだ論文は2021年にワトソンAIラボに所属する研究員によって投稿されたCrossVitについての論文です。私自身が機械学習の開発経験がない分どのモデルでもベースとなっている手法を探求したいと思っておりまして、調べたところトランスフォーマーがベースとなっていることが多いことを知りました。しかし、自然言語処理で主に用いられていることもあり、画像認識でもトランスフォーマーは用いられているのか調べたところVision Transformerについて手法が掲載されていたので知りたいと思い今回の論文を選定致しました。

# 概要
まずは概要の説明です。この論文がどんな論文であるかというと、大きく分けて2つの文にまとめました。スライドに載っている通りにはなりますが、
ViTでは画像パッチを同じサイズに区切っているのに対して大小異なるサイズのパッチに区切ることで異なるスケールの情報を取り扱うことができるCrossViTを提案しました。
その手法の提案によって、異なるサイズの画像パッチを組み合わせて強力な画像特徴を生成することができることを示し、画像分類におけるトランスフォーマーモデルの可能性と応用範囲を広げることがが可能となりました。

具体的な応用例でいうと、医療画像診断、物体検出、顔認識や表情分析などに用いられています。

# 新規性・結果・新たな知見
次に新規性について話していきます。
この論文からわかった新規性というのも手法に近いものではあるのですが、
新規性は、小さなパッチと大きなパッチを別々のトランスフォーマーに入力することです。
次のスライドで画像を用いて説明します。

内部で行われている処理について画像を追ってまとめます。
こちらの画像は論文から引用してます。
具体的に説明すると、入力画像を大小異なる2種類のパッチに分割し，それぞれのサイズごとにTransformerのEncoderに入力しています。
その後異なるサイズのパッチとのattentionを計算するcross-attentionを求め最後に2つのサイズから得られた特徴を結合しています。
この二つのブランチ間でトークンを融合するために囲われている赤い部分があると思うのですが、こちらはクロスアテンションモジュールを導入しています。このモジュールは、各ブランチから選択されたトークンをクエリとして使用し、他のブランチからすべてのトークンとアテンションを計算する。このようにして、各ブランチは他方から情報を受け取ることができる。

このクロスアテンションモジュールがなぜ用いられているかを調べたところ、二つのブランチ間で情報を交換するために必要な時間と空間の複雑さを線形に抑えることができるため用いられていることがわかりました。

## 実装結果:
実装結果として
CrossViTは、ViTやDeiTよりも高い精度を達成しました。特に、ImageNet1Kでは、DeiTよりも2%以上高い精度を示しました。実際の結果表を見ると、

CrossViTは、EfficientNetやResNetなどの効率的なCNNモデルとも競合する性能を持つようになりました。実験の結果表を見ると、

ImageNet1KやCIFAR-100などの標準的な画像分類データセットで、提案手法は最先端の視覚トランスフォーマーや効率的なCNNモデルと同等かそれ以上の性能を達成した。例えば、ImageNet1Kでは、いくつかのアーキテクチャ変更により、提案手法はFLOPsやモデルパラメータの小さなから中程度の増加で、最近のDeiTを2%以上大きく上回りました。また、CIFAR-100では、提案手法はResNet-50よりも約3倍少ないFLOPsで同等の精度を達成しました。

## 得られた知見
画像分類のためのトランスフォーマーモデルでは、多尺度の特徴表現を学習することが重要であることがわかった。
異なるサイズの画像パッチを組み合わせることで、より豊富な画像特徴を生成することができることがわかった。
クロスアテンションによるトークン融合は、計算量とメモリ量の観点からも効率的であり、ブランチ間の情報交換に有効であることがわかった。


=================================================================================
### 他に分かった結果
- CrossViTは、ImageNet1KやCIFAR-10/100などの標準的な画像分類データセットで評価された。
- CrossViTは、大規模なデータセット（ImageNet21K やJFT300M ）を事前学習に使用しなくても、良好な結果を得ることができる。
- 計算量やメモリ量を削減するために、各ブランチの単一のトークンをクエリとして使用して他の枝と情報を交換するというクロスアテンションというモジュールを開発した。このモジュールは、計算とメモリの複雑さの両方に対して線形時間しか必要とせず、それ以外では二次時間が必要である。

# 課題というか難しかった点
- この論文の貢献は、主に実験的なものであり、理論的な根拠や分析は不十分である。例えば、多尺度の特徴表現がなぜ有効なのか、クロスアテンションモジュールの位置がなぜ性能に影響するのか、などについては十分に説明されていない。
- この論文は、画像パッチのサイズを固定しており、動的に変化させることはできない。画像の内容に応じてパッチのサイズを調整することができれば、より柔軟な特徴表現が可能になるかもしれない。
- この論文は、クロスアテンションモジュールで各ブランチから単一のトークンをクエリとして使用している。これは、各ブランチの情報を十分に活用できているとは言えない。複数のトークンをクエリとして使用することができれば、より豊富な情報交換が可能になるかもしれない。ただし、これは計算量とメモリ量の増加につながる可能性がある。

# 役立つ場面
### 医療画像診断: 
この論文の手法は、画像分類のためのトランスフォーマーモデルの性能と効率性を向上させることができます。医療画像診断では、X線やMRIなどの画像から病気や異常を検出することが重要です。この論文の手法は、画像を小さく切って、それぞれに番号をつけるという手法を用いて、異なるサイズの画像パッチ（トランスフォーマーのトークン）を組み合わせて強力な画像特徴を生成することができます。これにより、画像から病気や異常を正確に分類することができる可能性があります。例えば、[こちら]の研究では、この論文の手法をCOVID-19の診断に応用しています。

### 自動運転: 
この論文の手法は、画像分類において最先端の性能を達成することができます。自動運転では、カメラやレーダーなどのセンサーから得られた画像から道路状況や障害物を判断することが重要です。この論文の手法は、画像を小さく切って、それぞれに番号をつけるという手法を用いて、異なるサイズの画像パッチ（トランスフォーマーのトークン）を組み合わせて強力な画像特徴を生成することができます。これにより、画像から道路状況や障害物を正確に分類することができる可能性があります。例えば、[こちら]の研究では、この論文の手法を自動運転に応用しています。

### 顔認識や表情分析: 
この論文の手法は、画像分類において最先端の性能を達成することができます。顔認識や表情分析では、カメラやスマートフォンなどから得られた人間の顔の画像から個人や感情を識別することが重要です。この論文の手法は、画像を小さく切って、それぞれに番号をつけるという手法を用いて、異なるサイズの画像パッチ（トランスフォーマーのトークン）を組み合わせて強力な画像特徴を生成することができます。これにより、画像から個人や感情を正確に分類することができる可能性があります。例えば、[こちら]の研究では、この論文の手法を顔認識や表情分析に応用しています。

# 参考文献
https://arxiv.org/pdf/2103.14899.pdf


